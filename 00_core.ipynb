{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hmc\n",
    "\n",
    "> API details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "\n",
    "import dipy.align as dpa\n",
    "from dipy.io.utils import read_img_arr_or_path\n",
    "from dipy.reconst.sfm import (SparseFascicleModel, SparseFascicleFit,\n",
    "                              IsotropicFit, IsotropicModel,\n",
    "                              _to_fit_iso, nanmean)\n",
    "import dipy.core.gradients as dpg\n",
    "import collections\n",
    "import nibabel as nib\n",
    "from sklearn.base import RegressorMixin\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial\n",
    "from scipy.linalg import svd \n",
    "svd = partial(svd, full_matrices=False)\n",
    "\n",
    "def _do_svd(X, y, jit=True):\n",
    "    \"\"\"\n",
    "    Helper function to produce SVD outputs\n",
    "    \"\"\"\n",
    "    if len(y.shape) == 1:\n",
    "        y = y[:, np.newaxis]\n",
    "\n",
    "    if X.shape[0] > X.shape[1]:\n",
    "        uu, ss, v_t = svd(X.T @ X)\n",
    "        selt = np.sqrt(ss)\n",
    "        if y.shape[-1] >= X.shape[0]:\n",
    "            ynew = (1/selt) @ v_t @ X.T @ y\n",
    "        else:\n",
    "            ynew = np.diag(1./selt) @ v_t @ (X.T @ y)\n",
    "\n",
    "    else:\n",
    "        uu, selt, v_t = svd(X)\n",
    "        # This rotates the targets by the unitary matrix uu.T:\n",
    "        ynew = uu.T @ y\n",
    "\n",
    "    ols_coef = (ynew.T / selt).T\n",
    "\n",
    "    return uu, selt, v_t, ols_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExponentialIsotropicModel(IsotropicModel):\n",
    "    \"\"\"\n",
    "    Representing the isotropic signal as a fit to an exponential decay function\n",
    "    with b-values\n",
    "    \"\"\"\n",
    "    def fit(self, data, mask=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ExponentialIsotropicFit class instance.\n",
    "        \"\"\"\n",
    "        to_fit = _to_fit_iso(data, self.gtab, mask=mask)\n",
    "        # Fitting to the log-transformed relative data is much faster:\n",
    "        nz_idx = to_fit > 0\n",
    "        to_fit[nz_idx] = np.log(to_fit[nz_idx])\n",
    "        to_fit[~nz_idx] = -np.inf\n",
    "        p = nanmean(to_fit / self.gtab.bvals[~self.gtab.b0s_mask], -1)\n",
    "        params = -p\n",
    "        if mask is None:\n",
    "            params = np.reshape(params, data.shape[:-1])\n",
    "        else:\n",
    "            out_params = np.zeros(data.shape[:-1])\n",
    "            out_params[mask] = params\n",
    "            params = out_params\n",
    "        return ExponentialIsotropicFit(self, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExponentialIsotropicFit(IsotropicFit):\n",
    "    \"\"\"\n",
    "    A fit to the ExponentialIsotropicModel object, based on data.\n",
    "    \"\"\"\n",
    "    def predict(self, gtab=None):\n",
    "        \"\"\"\n",
    "        Predict the isotropic signal, based on a gradient table. In this case,\n",
    "        the prediction will be for an exponential decay with the mean\n",
    "        diffusivity derived from the data that was fit.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gtab : a GradientTable class instance (optional)\n",
    "            Defaults to use the gtab from the IsotropicModel from which this\n",
    "            fit was derived.\n",
    "        \"\"\"\n",
    "        if gtab is None:\n",
    "            gtab = self.model.gtab\n",
    "        if len(self.params.shape) == 0:\n",
    "            pred = np.exp(-gtab.bvals[~gtab.b0s_mask] *\n",
    "                          (np.zeros(np.sum(~gtab.b0s_mask)) +\n",
    "                          self.params[..., np.newaxis]))\n",
    "        else:\n",
    "            pred = np.exp(-gtab.bvals[~gtab.b0s_mask] *\n",
    "                          (np.zeros((self.params.shape +\n",
    "                                     (int(np.sum(~gtab.b0s_mask)), ))) +\n",
    "                          self.params[..., np.newaxis]))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "BIG_BIAS = 10e3\n",
    "SMALL_BIAS = 10e-3\n",
    "BIAS_STEP = 0.2\n",
    "\n",
    "\n",
    "class SFM4HMC(SparseFascicleModel):\n",
    "    \"\"\"\n",
    "    We need to reimplement the fit, so that we can use the FRR cleverness\n",
    "    under the hood\n",
    "    \"\"\"\n",
    "    def fit(self, data, frac=0.5, mask=None, tol=10e-10, iso_params=None):\n",
    "        \"\"\"\n",
    "        Fit the SparseFascicleModel object to data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : array\n",
    "            The measured signal.\n",
    "\n",
    "        mask : array, optional\n",
    "            A boolean array used to mark the coordinates in the data that\n",
    "            should be analyzed. Has the shape `data.shape[:-1]`. Default: None,\n",
    "            which implies that all points should be analyzed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        SparseFascicleFit object\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            # Flatten it to 2D either way:\n",
    "            data_in_mask = np.reshape(data, (-1, data.shape[-1]))\n",
    "        else:\n",
    "            # Check for valid shape of the mask\n",
    "            if mask.shape != data.shape[:-1]:\n",
    "                raise ValueError(\"Mask is not the same shape as data.\")\n",
    "            mask = np.array(mask, dtype=bool, copy=False)\n",
    "            data_in_mask = np.reshape(data[mask], (-1, data.shape[-1]))\n",
    "\n",
    "        # Fitting is done on the relative signal (S/S0):\n",
    "        flat_S0 = np.mean(data_in_mask[..., self.gtab.b0s_mask], -1)\n",
    "        if not flat_S0.size or not flat_S0.max():\n",
    "            flat_S = np.zeros(data_in_mask[..., ~self.gtab.b0s_mask].shape)\n",
    "        else:\n",
    "            flat_S = (data_in_mask[..., ~self.gtab.b0s_mask] /\n",
    "                      flat_S0[..., None])\n",
    "\n",
    "        if iso_params is None:\n",
    "            isotropic = self.isotropic(self.gtab).fit(data, mask)            \n",
    "        else:\n",
    "            isotropic = ExponentialIsotropicFit(self.isotropic(self.gtab), iso_params)\n",
    "\n",
    "        isopredict = isotropic.predict()\n",
    "\n",
    "        if mask is None:\n",
    "            isopredict = np.reshape(isopredict, (-1, isopredict.shape[-1]))\n",
    "        else:\n",
    "            isopredict = isopredict[mask]\n",
    "\n",
    "        # Here's where things get different: ##\n",
    "        y = (flat_S - isopredict).T\n",
    "        # Making sure nan voxels get 0 params:\n",
    "        nan_targets = np.unique(np.where(~np.isfinite(y))[1])\n",
    "        y[:, nan_targets] = 0\n",
    "\n",
    "        ### FIT FRACRIDGE\n",
    "        X = self.design_matrix\n",
    "        uu, selt, v_t, ols_coef = _do_svd(X, y)\n",
    "        # Set solutions for small eigenvalues to 0 for all targets:\n",
    "        isbad = selt < tol\n",
    "        if np.any(isbad):\n",
    "            warnings.warn(\"Some eigenvalues are being treated as 0\")\n",
    "\n",
    "        alpha=frac\n",
    "        ols_coef[isbad, ...] = 0\n",
    "        seltsq = selt**2\n",
    "        sclg = seltsq / (seltsq + alpha)\n",
    "        coef = sclg[:, np.newaxis] * ols_coef\n",
    "        coef = v_t.T @ coef\n",
    "        # # Limits on the grid of candidate alphas used for interpolation:\n",
    "        # val1 = BIG_BIAS * selt[0] ** 2\n",
    "        # val2 = SMALL_BIAS * selt[-1] ** 2\n",
    "\n",
    "        # # Generates the grid of candidate alphas used in interpolation:\n",
    "        # alphagrid = np.concatenate(\n",
    "        #     [np.array([0]),\n",
    "        #     10 ** np.arange(np.floor(np.log10(val2)),\n",
    "        #                     np.ceil(np.log10(val1)), BIAS_STEP)])\n",
    "\n",
    "        # # The scaling factor applied to coefficients in the rotated space is\n",
    "        # # lambda**2 / (lambda**2 + alpha), where lambda are the singular values\n",
    "        # seltsq = selt**2\n",
    "        # sclg = seltsq / (seltsq + alphagrid[:, None])\n",
    "        # sclg_sq = sclg**2\n",
    "        # bb = y.shape[-1]\n",
    "        # ff = 1\n",
    "\n",
    "        # # Prellocate the solution:\n",
    "        # coef = np.empty((X.shape[0], bb))\n",
    "        # alphas = np.empty((ff, bb))\n",
    "\n",
    "        # # The main loop is over targets:\n",
    "        # for ii in range(y.shape[-1]):\n",
    "        #     # Applies the scaling factors per alpha\n",
    "        #     newlen = np.sqrt(sclg_sq @ ols_coef[..., ii]**2).T\n",
    "        #     # Normalize to the length of the unregularized solution,\n",
    "        #     # because (alphagrid[0] == 0)\n",
    "        #     newlen = (newlen / newlen[0])\n",
    "        #     # Perform interpolation in a log transformed space (so it behaves\n",
    "        #     # nicely), avoiding log of 0.\n",
    "        #     temp = np.interp(frac, newlen[::-1], np.log(1 + alphagrid)[::-1])\n",
    "        #     # Undo the log transform from the previous step\n",
    "        #     targetalphas = np.exp(temp) - 1\n",
    "        #     # Allocate the alphas for this target:\n",
    "        #     alphas[:, ii] = targetalphas\n",
    "        #     # Calculate the new scaling factor, based on the interpolated alphas:\n",
    "        #     sc = seltsq / (seltsq + targetalphas[np.newaxis].T)\n",
    "        #     # Use the scaling factor to calculate coefficients in the rotated\n",
    "        #     # space:\n",
    "        #     coef[..., ii] = (sc * ols_coef[..., ii]).T\n",
    "\n",
    "        # # After iterating over all targets, we unrotate using the unitary v\n",
    "        # # matrix and reshape to conform to desired output:\n",
    "        # coef = np.reshape(v_t.T @ coef.reshape((X.shape[0], ff * bb)),\n",
    "        #                 (X.shape[1], ff, bb))\n",
    "\n",
    "        flat_params = coef.squeeze().T\n",
    "\n",
    "        # flat_params = self.solver.fit(self.design_matrix, y).coef_.T\n",
    "\n",
    "        # We avoid this loop over the data: ##\n",
    "        # for vox, vox_data in enumerate(flat_S):\n",
    "        #     # In voxels in which S0 is 0, we just want to keep the\n",
    "        #     # parameters at all-zeros, and avoid nasty sklearn errors:\n",
    "        #     if not (np.any(~np.isfinite(vox_data)) or np.all(vox_data == 0)):\n",
    "        #         fit_it = vox_data - isopredict[vox]\n",
    "        #         with warnings.catch_warnings():\n",
    "        #             warnings.simplefilter(\"ignore\")\n",
    "        #             flat_params[vox] = self.solver.fit(self.design_matrix,\n",
    "        #                                                fit_it).coef_\n",
    "\n",
    "        if mask is None:\n",
    "            out_shape = data.shape[:-1] + (-1, )\n",
    "            beta = flat_params.reshape(out_shape)\n",
    "            S0 = flat_S0.reshape(data.shape[:-1])\n",
    "        else:\n",
    "            beta = np.zeros(data.shape[:-1] +\n",
    "                            (self.design_matrix.shape[-1],))\n",
    "            beta[mask, :] = flat_params\n",
    "            S0 = np.zeros(data.shape[:-1])\n",
    "            S0[mask] = flat_S0\n",
    "\n",
    "        return SparseFascicleFit(self, beta, S0, isotropic), isotropic.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FRR4SFM(FracRidgeRegressor, RegressorMixin):\n",
    "#     def __init__(self, fracs=None, fit_intercept=False, normalize=False,\n",
    "#                  copy_X=True, tol=1e-10, jit=True):\n",
    "#         FracRidgeRegressor.__init__(\n",
    "#             self, fracs=fracs, fit_intercept=False, normalize=False,\n",
    "#             copy_X=True, tol=tol, jit=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prep_data(gtab, data, mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(data.shape[:3]).astype(bool)\n",
    "    b0 = np.mean(data[mask][:, gtab.b0s_mask], -1)\n",
    "    dwi = data[mask][:, ~gtab.b0s_mask] / b0[np.newaxis].T\n",
    "    return dwi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prep_sfm(gtab, data, mask=None):\n",
    "    y = prep_data(gtab, data, mask)\n",
    "    isotropic = ExponentialIsotropicModel(gtab)\n",
    "    sfm = SparseFascicleModel(gtab)#, isotropic=isotropic)\n",
    "    X = sfm.design_matrix\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.data import get_fnames\n",
    "from dipy.core.gradients import gradient_table\n",
    "\n",
    "fdata, fbvals, fbvecs = get_fnames(\"sherbrooke_3shell\")\n",
    "gtab = gradient_table(fbvals, fbvecs, b0_threshold=0)\n",
    "img = nib.load(fdata)\n",
    "data = img.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We fix b0 to be one volume, registered to one of the\n",
    "# # b0 volumes (first, per default):\n",
    "# if np.sum(gtab.b0s_mask) > 1:\n",
    "#     b0_img = nib.Nifti1Image(data[..., gtab.b0s_mask], affine)\n",
    "#     trans_b0, b0_affines = dpa.register_series(b0_img, ref=b0_ref)\n",
    "#     ref_data = np.mean(trans_b0, -1)[..., np.newaxis]\n",
    "# else:\n",
    "#     # There's only one b0 and we register everything to it\n",
    "#     trans_b0 = ref_data = data[..., gtab.b0s_mask]\n",
    "\n",
    "# moving_data = data[..., ~gtab.b0s_mask]\n",
    "# moving_bvals = gtab.bvals[~gtab.b0s_mask]\n",
    "# moving_bvecs = gtab.bvecs[~gtab.b0s_mask]\n",
    "# mask = np.ones(ref_data.shape[:3])\n",
    "# mask[np.where(ref_data[..., 0] == 0)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loo = 0 \n",
    "# loo_idxer = np.ones(moving_data.shape[-1]).astype(bool)\n",
    "# loo_idxer[loo] = False\n",
    "\n",
    "# in_data = np.concatenate([ref_data, moving_data[..., loo_idxer]], -1)\n",
    "# in_gtab = dpg.gradient_table(\n",
    "#     np.concatenate([np.array([0]), moving_bvals[loo_idxer]]),\n",
    "#     np.concatenate([np.array([[0, 0, 0]]), moving_bvecs[loo_idxer]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfm = SFM4HMC(\n",
    "#     in_gtab,\n",
    "#     isotropic=ExponentialIsotropicModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sff = sfm.fit(in_data, mask=mask, frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = sff.predict(in_gtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(in_data[64, 64, 30])\n",
    "# plt.plot(pred[64, 64, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_data = moving_data[..., ~loo_idxer]\n",
    "# out_gtab = dpg.gradient_table(moving_bvals[~loo_idxer],\n",
    "#                                 moving_bvecs[~loo_idxer])\n",
    "\n",
    "# out_pred = sff.predict(out_gtab, S0=ref_data[..., 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_data.shape, out_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo = np.sqrt((out_data[:, :, 30, 0] - out_pred[:, :, 30])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(out_data[:, :, 30])\n",
    "# plt.matshow(out_pred[:, :, 30], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(out_data), np.max(out_pred), np.min(out_data), np.min(out_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hmc(data, gtab, mask=None, b0_ref=0, affine=None):\n",
    "    data, affine = read_img_arr_or_path(data, affine=affine)\n",
    "    if isinstance(gtab, collections.Sequence):\n",
    "        gtab = dpg.gradient_table(*gtab)\n",
    "\n",
    "    # We fix b0 to be one volume, registered to one of the\n",
    "    # b0 volumes (first, per default):\n",
    "    if np.sum(gtab.b0s_mask) > 1:\n",
    "        b0_img = nib.Nifti1Image(data[..., gtab.b0s_mask], affine)\n",
    "        trans_b0, b0_affines = dpa.register_series(b0_img, ref=b0_ref)\n",
    "        ref_data = np.mean(trans_b0, -1)[..., np.newaxis]\n",
    "    else:\n",
    "        # There's only one b0 and we register everything to it\n",
    "        trans_b0 = ref_data = data[..., gtab.b0s_mask]\n",
    "\n",
    "    moving_data = data[..., ~gtab.b0s_mask]\n",
    "    moving_bvals = gtab.bvals[~gtab.b0s_mask]\n",
    "    moving_bvecs = gtab.bvecs[~gtab.b0s_mask]\n",
    "    mask = np.ones(ref_data.shape[:3])\n",
    "    mask[np.where(ref_data[..., 0] == 0)] = 0\n",
    "    moved = []\n",
    "    affines = []\n",
    "\n",
    "    # We fit the isotropic prediction once for all the data:\n",
    "    sfm_all = SFM4HMC(\n",
    "        gtab,\n",
    "        isotropic=ExponentialIsotropicModel)\n",
    "\n",
    "    sff_all, iso_params = sfm_all.fit(data, frac=0.5, mask=mask, tol=10e-10, iso_params=None)\n",
    "\n",
    "    for loo in range(3): #range(moving_data.shape[-1]):\n",
    "        print(loo)\n",
    "        loo_idxer = np.ones(moving_data.shape[-1]).astype(bool)\n",
    "        loo_idxer[loo] = False\n",
    "\n",
    "        in_data = np.concatenate([ref_data, moving_data[..., loo_idxer]], -1)\n",
    "        in_gtab = dpg.gradient_table(\n",
    "            np.concatenate([np.array([0]), moving_bvals[loo_idxer]]),\n",
    "            np.concatenate([np.array([[0, 0, 0]]), moving_bvecs[loo_idxer]]))\n",
    "\n",
    "        sfm = SFM4HMC(\n",
    "            in_gtab,\n",
    "            isotropic=ExponentialIsotropicModel)\n",
    "\n",
    "        t1 = time.time()\n",
    "        sff, _ = sfm.fit(in_data, mask=mask, frac=10e-10, iso_params=iso_params)\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        out_data = moving_data[..., ~loo_idxer]\n",
    "        out_gtab = dpg.gradient_table(moving_bvals[~loo_idxer],\n",
    "                                      moving_bvecs[~loo_idxer])\n",
    "\n",
    "        out_pred = sff.predict(out_gtab, S0=ref_data[..., 0])\n",
    "        t1 = time.time()\n",
    "        resampled, starting_affine = dpa.affine_registration(\n",
    "            out_data[..., 0],\n",
    "            out_pred,\n",
    "            moving_affine=affine,\n",
    "            static_affine=affine,\n",
    "            pipeline=[dpa.affine],\n",
    "            level_iters=[10])\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        moved.append(resampled)\n",
    "        affines.append(starting_affine)\n",
    "        in_data[..., loo] = resampled\n",
    "        # XXX Also rotate the b-vector here\n",
    "    return sff, in_gtab, in_data\n",
    "\n",
    "# Reuse USV from a single SVD decomposition of X at the beginning of each\n",
    "# loop through all of the volumes. Should speed up the RR fit in every volume.\n",
    "# <= We can't do that, because the directions are different each time\n",
    "\n",
    "# Use a sliding window to fit only to n nearest neighbors.\n",
    "\n",
    "# Fit isotropic component once per voxel and be done with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc(data, gtab, mask=None, b0_ref=0, affine=img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25.745349168777466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 67.6421 s\n",
      "File: <ipython-input-7-db6c483b130e>\n",
      "Function: fit at line 12\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    12                                               def fit(self, data, frac=0.5, mask=None, tol=10e-10, iso_params=None):\n",
      "    13                                                   \"\"\"\n",
      "    14                                                   Fit the SparseFascicleModel object to data.\n",
      "    15                                           \n",
      "    16                                                   Parameters\n",
      "    17                                                   ----------\n",
      "    18                                                   data : array\n",
      "    19                                                       The measured signal.\n",
      "    20                                           \n",
      "    21                                                   mask : array, optional\n",
      "    22                                                       A boolean array used to mark the coordinates in the data that\n",
      "    23                                                       should be analyzed. Has the shape `data.shape[:-1]`. Default: None,\n",
      "    24                                                       which implies that all points should be analyzed.\n",
      "    25                                           \n",
      "    26                                                   Returns\n",
      "    27                                                   -------\n",
      "    28                                                   SparseFascicleFit object\n",
      "    29                                                   \"\"\"\n",
      "    30         2          5.0      2.5      0.0          if mask is None:\n",
      "    31                                                       # Flatten it to 2D either way:\n",
      "    32                                                       data_in_mask = np.reshape(data, (-1, data.shape[-1]))\n",
      "    33                                                   else:\n",
      "    34                                                       # Check for valid shape of the mask\n",
      "    35         2          4.0      2.0      0.0              if mask.shape != data.shape[:-1]:\n",
      "    36                                                           raise ValueError(\"Mask is not the same shape as data.\")\n",
      "    37         2       1248.0    624.0      0.0              mask = np.array(mask, dtype=bool, copy=False)\n",
      "    38         2    9132041.0 4566020.5     13.5              data_in_mask = np.reshape(data[mask], (-1, data.shape[-1]))\n",
      "    39                                           \n",
      "    40                                                   # Fitting is done on the relative signal (S/S0):\n",
      "    41         2      74651.0  37325.5      0.1          flat_S0 = np.mean(data_in_mask[..., self.gtab.b0s_mask], -1)\n",
      "    42         2       1138.0    569.0      0.0          if not flat_S0.size or not flat_S0.max():\n",
      "    43                                                       flat_S = np.zeros(data_in_mask[..., ~self.gtab.b0s_mask].shape)\n",
      "    44                                                   else:\n",
      "    45         4    5432341.0 1358085.2      8.0              flat_S = (data_in_mask[..., ~self.gtab.b0s_mask] /\n",
      "    46         2         13.0      6.5      0.0                        flat_S0[..., None])\n",
      "    47                                           \n",
      "    48         2          6.0      3.0      0.0          if iso_params is None:\n",
      "    49         1   19578587.0 19578587.0     28.9              isotropic = self.isotropic(self.gtab).fit(data, mask)            \n",
      "    50                                                   else:\n",
      "    51         1         16.0     16.0      0.0              isotropic = ExponentialIsotropicFit(self.isotropic(self.gtab), iso_params)\n",
      "    52                                           \n",
      "    53         2    6980482.0 3490241.0     10.3          isopredict = isotropic.predict()\n",
      "    54                                           \n",
      "    55         2          6.0      3.0      0.0          if mask is None:\n",
      "    56                                                       isopredict = np.reshape(isopredict, (-1, isopredict.shape[-1]))\n",
      "    57                                                   else:\n",
      "    58         2    1563208.0 781604.0      2.3              isopredict = isopredict[mask]\n",
      "    59                                           \n",
      "    60                                                   # Here's where things get different: ##\n",
      "    61         2    1972901.0 986450.5      2.9          y = (flat_S - isopredict).T\n",
      "    62                                                   # Making sure nan voxels get 0 params:\n",
      "    63         2    3558965.0 1779482.5      5.3          nan_targets = np.unique(np.where(~np.isfinite(y))[1])\n",
      "    64         2         32.0     16.0      0.0          y[:, nan_targets] = 0\n",
      "    65                                           \n",
      "    66                                                   ### FIT FRACRIDGE\n",
      "    67         2    1174780.0 587390.0      1.7          X = self.design_matrix\n",
      "    68         2    4495826.0 2247913.0      6.6          uu, selt, v_t, ols_coef = _do_svd(X, y)\n",
      "    69                                                   # Set solutions for small eigenvalues to 0 for all targets:\n",
      "    70         2         40.0     20.0      0.0          isbad = selt < tol\n",
      "    71         2         84.0     42.0      0.0          if np.any(isbad):\n",
      "    72         2         55.0     27.5      0.0              warnings.warn(\"Some eigenvalues are being treated as 0\")\n",
      "    73                                           \n",
      "    74         2          2.0      1.0      0.0          alpha=frac\n",
      "    75         2      24289.0  12144.5      0.0          ols_coef[isbad, ...] = 0\n",
      "    76         2         33.0     16.5      0.0          seltsq = selt**2\n",
      "    77         2         19.0      9.5      0.0          sclg = seltsq / (seltsq + alpha)\n",
      "    78         2    1473226.0 736613.0      2.2          coef = sclg[:, np.newaxis] * ols_coef\n",
      "    79         2    6809101.0 3404550.5     10.1          coef = v_t.T @ coef\n",
      "    80                                                   # # Limits on the grid of candidate alphas used for interpolation:\n",
      "    81                                                   # val1 = BIG_BIAS * selt[0] ** 2\n",
      "    82                                                   # val2 = SMALL_BIAS * selt[-1] ** 2\n",
      "    83                                           \n",
      "    84                                                   # # Generates the grid of candidate alphas used in interpolation:\n",
      "    85                                                   # alphagrid = np.concatenate(\n",
      "    86                                                   #     [np.array([0]),\n",
      "    87                                                   #     10 ** np.arange(np.floor(np.log10(val2)),\n",
      "    88                                                   #                     np.ceil(np.log10(val1)), BIAS_STEP)])\n",
      "    89                                           \n",
      "    90                                                   # # The scaling factor applied to coefficients in the rotated space is\n",
      "    91                                                   # # lambda**2 / (lambda**2 + alpha), where lambda are the singular values\n",
      "    92                                                   # seltsq = selt**2\n",
      "    93                                                   # sclg = seltsq / (seltsq + alphagrid[:, None])\n",
      "    94                                                   # sclg_sq = sclg**2\n",
      "    95                                                   # bb = y.shape[-1]\n",
      "    96                                                   # ff = 1\n",
      "    97                                           \n",
      "    98                                                   # # Prellocate the solution:\n",
      "    99                                                   # coef = np.empty((X.shape[0], bb))\n",
      "   100                                                   # alphas = np.empty((ff, bb))\n",
      "   101                                           \n",
      "   102                                                   # # The main loop is over targets:\n",
      "   103                                                   # for ii in range(y.shape[-1]):\n",
      "   104                                                   #     # Applies the scaling factors per alpha\n",
      "   105                                                   #     newlen = np.sqrt(sclg_sq @ ols_coef[..., ii]**2).T\n",
      "   106                                                   #     # Normalize to the length of the unregularized solution,\n",
      "   107                                                   #     # because (alphagrid[0] == 0)\n",
      "   108                                                   #     newlen = (newlen / newlen[0])\n",
      "   109                                                   #     # Perform interpolation in a log transformed space (so it behaves\n",
      "   110                                                   #     # nicely), avoiding log of 0.\n",
      "   111                                                   #     temp = np.interp(frac, newlen[::-1], np.log(1 + alphagrid)[::-1])\n",
      "   112                                                   #     # Undo the log transform from the previous step\n",
      "   113                                                   #     targetalphas = np.exp(temp) - 1\n",
      "   114                                                   #     # Allocate the alphas for this target:\n",
      "   115                                                   #     alphas[:, ii] = targetalphas\n",
      "   116                                                   #     # Calculate the new scaling factor, based on the interpolated alphas:\n",
      "   117                                                   #     sc = seltsq / (seltsq + targetalphas[np.newaxis].T)\n",
      "   118                                                   #     # Use the scaling factor to calculate coefficients in the rotated\n",
      "   119                                                   #     # space:\n",
      "   120                                                   #     coef[..., ii] = (sc * ols_coef[..., ii]).T\n",
      "   121                                           \n",
      "   122                                                   # # After iterating over all targets, we unrotate using the unitary v\n",
      "   123                                                   # # matrix and reshape to conform to desired output:\n",
      "   124                                                   # coef = np.reshape(v_t.T @ coef.reshape((X.shape[0], ff * bb)),\n",
      "   125                                                   #                 (X.shape[1], ff, bb))\n",
      "   126                                           \n",
      "   127         2         82.0     41.0      0.0          flat_params = coef.squeeze().T\n",
      "   128                                           \n",
      "   129                                                   # flat_params = self.solver.fit(self.design_matrix, y).coef_.T\n",
      "   130                                           \n",
      "   131                                                   # We avoid this loop over the data: ##\n",
      "   132                                                   # for vox, vox_data in enumerate(flat_S):\n",
      "   133                                                   #     # In voxels in which S0 is 0, we just want to keep the\n",
      "   134                                                   #     # parameters at all-zeros, and avoid nasty sklearn errors:\n",
      "   135                                                   #     if not (np.any(~np.isfinite(vox_data)) or np.all(vox_data == 0)):\n",
      "   136                                                   #         fit_it = vox_data - isopredict[vox]\n",
      "   137                                                   #         with warnings.catch_warnings():\n",
      "   138                                                   #             warnings.simplefilter(\"ignore\")\n",
      "   139                                                   #             flat_params[vox] = self.solver.fit(self.design_matrix,\n",
      "   140                                                   #                                                fit_it).coef_\n",
      "   141                                           \n",
      "   142         2          3.0      1.5      0.0          if mask is None:\n",
      "   143                                                       out_shape = data.shape[:-1] + (-1, )\n",
      "   144                                                       beta = flat_params.reshape(out_shape)\n",
      "   145                                                       S0 = flat_S0.reshape(data.shape[:-1])\n",
      "   146                                                   else:\n",
      "   147         4        146.0     36.5      0.0              beta = np.zeros(data.shape[:-1] +\n",
      "   148         2          5.0      2.5      0.0                              (self.design_matrix.shape[-1],))\n",
      "   149         2    5363255.0 2681627.5      7.9              beta[mask, :] = flat_params\n",
      "   150         2       2999.0   1499.5      0.0              S0 = np.zeros(data.shape[:-1])\n",
      "   151         2       2486.0   1243.0      0.0              S0[mask] = flat_S0\n",
      "   152                                           \n",
      "   153         2         29.0     14.5      0.0          return SparseFascicleFit(self, beta, S0, isotropic), isotropic.params"
     ]
    }
   ],
   "source": [
    "%lprun -f SFM4HMC.fit sff, in_gtab, in_data = hmc(data, gtab, mask=None, b0_ref=0, affine=img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
