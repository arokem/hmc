{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hmc\n",
    "\n",
    "> API details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dipy.align as dpa\n",
    "from dipy.io.utils import read_img_arr_or_path\n",
    "from dipy.reconst.sfm import (SparseFascicleModel, SparseFascicleFit,\n",
    "                              IsotropicFit, IsotropicModel,\n",
    "                              _to_fit_iso, nanmean)\n",
    "import dipy.core.gradients as dpg\n",
    "import collections\n",
    "import nibabel as nib\n",
    "from sklearn.base import RegressorMixin\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy.linalg import svd \n",
    "svd = partial(svd, full_matrices=False)\n",
    "\n",
    "def _do_svd(X, y, jit=True):\n",
    "    \"\"\"\n",
    "    Helper function to produce SVD outputs\n",
    "    \"\"\"\n",
    "    if len(y.shape) == 1:\n",
    "        y = y[:, np.newaxis]\n",
    "\n",
    "    if X.shape[0] > X.shape[1]:\n",
    "        uu, ss, v_t = svd(X.T @ X)\n",
    "        selt = np.sqrt(ss)\n",
    "        if y.shape[-1] >= X.shape[0]:\n",
    "            ynew = (1/selt) @ v_t @ X.T @ y\n",
    "        else:\n",
    "            ynew = np.diag(1./selt) @ v_t @ (X.T @ y)\n",
    "\n",
    "    else:\n",
    "        uu, selt, v_t = svd(X)\n",
    "        # This rotates the targets by the unitary matrix uu.T:\n",
    "        ynew = uu.T @ y\n",
    "\n",
    "    ols_coef = (ynew.T / selt).T\n",
    "\n",
    "    return uu, selt, v_t, ols_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialIsotropicModel(IsotropicModel):\n",
    "    \"\"\"\n",
    "    Representing the isotropic signal as a fit to an exponential decay function\n",
    "    with b-values\n",
    "    \"\"\"\n",
    "    def fit(self, data, mask=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ExponentialIsotropicFit class instance.\n",
    "        \"\"\"\n",
    "        to_fit = _to_fit_iso(data, self.gtab, mask=mask)\n",
    "        # Fitting to the log-transformed relative data is much faster:\n",
    "        nz_idx = to_fit > 0\n",
    "        to_fit[nz_idx] = np.log(to_fit[nz_idx])\n",
    "        to_fit[~nz_idx] = -np.inf\n",
    "        p = nanmean(to_fit / self.gtab.bvals[~self.gtab.b0s_mask], -1)\n",
    "        params = -p\n",
    "        if mask is None:\n",
    "            params = np.reshape(params, data.shape[:-1])\n",
    "        else:\n",
    "            out_params = np.zeros(data.shape[:-1])\n",
    "            out_params[mask] = params\n",
    "            params = out_params\n",
    "        return ExponentialIsotropicFit(self, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialIsotropicFit(IsotropicFit):\n",
    "    \"\"\"\n",
    "    A fit to the ExponentialIsotropicModel object, based on data.\n",
    "    \"\"\"\n",
    "    def predict(self, gtab=None):\n",
    "        \"\"\"\n",
    "        Predict the isotropic signal, based on a gradient table. In this case,\n",
    "        the prediction will be for an exponential decay with the mean\n",
    "        diffusivity derived from the data that was fit.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gtab : a GradientTable class instance (optional)\n",
    "            Defaults to use the gtab from the IsotropicModel from which this\n",
    "            fit was derived.\n",
    "        \"\"\"\n",
    "        if gtab is None:\n",
    "            gtab = self.model.gtab\n",
    "        if len(self.params.shape) == 0:\n",
    "            pred = np.exp(-gtab.bvals[~gtab.b0s_mask] *\n",
    "                          (np.zeros(np.sum(~gtab.b0s_mask)) +\n",
    "                          self.params[..., np.newaxis]))\n",
    "        else:\n",
    "            pred = np.exp(-gtab.bvals[~gtab.b0s_mask] *\n",
    "                          (np.zeros((self.params.shape +\n",
    "                                     (int(np.sum(~gtab.b0s_mask)), ))) +\n",
    "                          self.params[..., np.newaxis]))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_BIAS = 10e3\n",
    "SMALL_BIAS = 10e-3\n",
    "BIAS_STEP = 0.2\n",
    "\n",
    "\n",
    "class SFM4HMC(SparseFascicleModel):\n",
    "    \"\"\"\n",
    "    We need to reimplement the fit, so that we can use the FRR cleverness\n",
    "    under the hood\n",
    "    \"\"\"\n",
    "    def fit(self, data, frac=0.5, mask=None, tol=10e-10):\n",
    "        \"\"\"\n",
    "        Fit the SparseFascicleModel object to data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : array\n",
    "            The measured signal.\n",
    "\n",
    "        mask : array, optional\n",
    "            A boolean array used to mark the coordinates in the data that\n",
    "            should be analyzed. Has the shape `data.shape[:-1]`. Default: None,\n",
    "            which implies that all points should be analyzed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        SparseFascicleFit object\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            # Flatten it to 2D either way:\n",
    "            data_in_mask = np.reshape(data, (-1, data.shape[-1]))\n",
    "        else:\n",
    "            # Check for valid shape of the mask\n",
    "            if mask.shape != data.shape[:-1]:\n",
    "                raise ValueError(\"Mask is not the same shape as data.\")\n",
    "            mask = np.array(mask, dtype=bool, copy=False)\n",
    "            data_in_mask = np.reshape(data[mask], (-1, data.shape[-1]))\n",
    "\n",
    "        # Fitting is done on the relative signal (S/S0):\n",
    "        flat_S0 = np.mean(data_in_mask[..., self.gtab.b0s_mask], -1)\n",
    "        if not flat_S0.size or not flat_S0.max():\n",
    "            flat_S = np.zeros(data_in_mask[..., ~self.gtab.b0s_mask].shape)\n",
    "        else:\n",
    "            flat_S = (data_in_mask[..., ~self.gtab.b0s_mask] /\n",
    "                      flat_S0[..., None])\n",
    "        isotropic = self.isotropic(self.gtab).fit(data, mask)\n",
    "\n",
    "        # We don't need to preallocate: ##\n",
    "        # flat_params = np.zeros((data_in_mask.shape[0],\n",
    "        #                         self.design_matrix.shape[-1]))\n",
    "\n",
    "        isopredict = isotropic.predict()\n",
    "\n",
    "        if mask is None:\n",
    "            isopredict = np.reshape(isopredict, (-1, isopredict.shape[-1]))\n",
    "        else:\n",
    "            isopredict = isopredict[mask]\n",
    "\n",
    "        # Here's where things get different: ##\n",
    "        y = (flat_S - isopredict).T\n",
    "        # Making sure nan voxels get 0 params:\n",
    "        nan_targets = np.unique(np.where(~np.isfinite(y))[1])\n",
    "        y[:, nan_targets] = 0\n",
    "\n",
    "        ### FIT FRACRIDGE\n",
    "        X = self.design_matrix\n",
    "        uu, selt, v_t, ols_coef = _do_svd(X, y)\n",
    "        # Set solutions for small eigenvalues to 0 for all targets:\n",
    "        isbad = selt < tol\n",
    "        if np.any(isbad):\n",
    "            warnings.warn(\"Some eigenvalues are being treated as 0\")\n",
    "\n",
    "        alpha=frac\n",
    "        ols_coef[isbad, ...] = 0\n",
    "        seltsq = selt**2\n",
    "        sclg = seltsq / (seltsq + alpha)\n",
    "        coef = sclg[:, np.newaxis] * ols_coef\n",
    "        coef = v_t.T @ coef\n",
    "        # # Limits on the grid of candidate alphas used for interpolation:\n",
    "        # val1 = BIG_BIAS * selt[0] ** 2\n",
    "        # val2 = SMALL_BIAS * selt[-1] ** 2\n",
    "\n",
    "        # # Generates the grid of candidate alphas used in interpolation:\n",
    "        # alphagrid = np.concatenate(\n",
    "        #     [np.array([0]),\n",
    "        #     10 ** np.arange(np.floor(np.log10(val2)),\n",
    "        #                     np.ceil(np.log10(val1)), BIAS_STEP)])\n",
    "\n",
    "        # # The scaling factor applied to coefficients in the rotated space is\n",
    "        # # lambda**2 / (lambda**2 + alpha), where lambda are the singular values\n",
    "        # seltsq = selt**2\n",
    "        # sclg = seltsq / (seltsq + alphagrid[:, None])\n",
    "        # sclg_sq = sclg**2\n",
    "        # bb = y.shape[-1]\n",
    "        # ff = 1\n",
    "\n",
    "        # # Prellocate the solution:\n",
    "        # coef = np.empty((X.shape[0], bb))\n",
    "        # alphas = np.empty((ff, bb))\n",
    "\n",
    "        # # The main loop is over targets:\n",
    "        # for ii in range(y.shape[-1]):\n",
    "        #     # Applies the scaling factors per alpha\n",
    "        #     newlen = np.sqrt(sclg_sq @ ols_coef[..., ii]**2).T\n",
    "        #     # Normalize to the length of the unregularized solution,\n",
    "        #     # because (alphagrid[0] == 0)\n",
    "        #     newlen = (newlen / newlen[0])\n",
    "        #     # Perform interpolation in a log transformed space (so it behaves\n",
    "        #     # nicely), avoiding log of 0.\n",
    "        #     temp = np.interp(frac, newlen[::-1], np.log(1 + alphagrid)[::-1])\n",
    "        #     # Undo the log transform from the previous step\n",
    "        #     targetalphas = np.exp(temp) - 1\n",
    "        #     # Allocate the alphas for this target:\n",
    "        #     alphas[:, ii] = targetalphas\n",
    "        #     # Calculate the new scaling factor, based on the interpolated alphas:\n",
    "        #     sc = seltsq / (seltsq + targetalphas[np.newaxis].T)\n",
    "        #     # Use the scaling factor to calculate coefficients in the rotated\n",
    "        #     # space:\n",
    "        #     coef[..., ii] = (sc * ols_coef[..., ii]).T\n",
    "\n",
    "        # # After iterating over all targets, we unrotate using the unitary v\n",
    "        # # matrix and reshape to conform to desired output:\n",
    "        # coef = np.reshape(v_t.T @ coef.reshape((X.shape[0], ff * bb)),\n",
    "        #                 (X.shape[1], ff, bb))\n",
    "\n",
    "        flat_params = coef.squeeze().T\n",
    "\n",
    "        # flat_params = self.solver.fit(self.design_matrix, y).coef_.T\n",
    "\n",
    "        # We avoid this loop over the data: ##\n",
    "        # for vox, vox_data in enumerate(flat_S):\n",
    "        #     # In voxels in which S0 is 0, we just want to keep the\n",
    "        #     # parameters at all-zeros, and avoid nasty sklearn errors:\n",
    "        #     if not (np.any(~np.isfinite(vox_data)) or np.all(vox_data == 0)):\n",
    "        #         fit_it = vox_data - isopredict[vox]\n",
    "        #         with warnings.catch_warnings():\n",
    "        #             warnings.simplefilter(\"ignore\")\n",
    "        #             flat_params[vox] = self.solver.fit(self.design_matrix,\n",
    "        #                                                fit_it).coef_\n",
    "\n",
    "        if mask is None:\n",
    "            out_shape = data.shape[:-1] + (-1, )\n",
    "            beta = flat_params.reshape(out_shape)\n",
    "            S0 = flat_S0.reshape(data.shape[:-1])\n",
    "        else:\n",
    "            beta = np.zeros(data.shape[:-1] +\n",
    "                            (self.design_matrix.shape[-1],))\n",
    "            beta[mask, :] = flat_params\n",
    "            S0 = np.zeros(data.shape[:-1])\n",
    "            S0[mask] = flat_S0\n",
    "\n",
    "        return SparseFascicleFit(self, beta, S0, isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FRR4SFM(FracRidgeRegressor, RegressorMixin):\n",
    "#     def __init__(self, fracs=None, fit_intercept=False, normalize=False,\n",
    "#                  copy_X=True, tol=1e-10, jit=True):\n",
    "#         FracRidgeRegressor.__init__(\n",
    "#             self, fracs=fracs, fit_intercept=False, normalize=False,\n",
    "#             copy_X=True, tol=tol, jit=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(gtab, data, mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(data.shape[:3]).astype(bool)\n",
    "    b0 = np.mean(data[mask][:, gtab.b0s_mask], -1)\n",
    "    dwi = data[mask][:, ~gtab.b0s_mask] / b0[np.newaxis].T\n",
    "    return dwi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sfm(gtab, data, mask=None):\n",
    "    y = prep_data(gtab, data, mask)\n",
    "    isotropic = ExponentialIsotropicModel(gtab)\n",
    "    sfm = SparseFascicleModel(gtab)#, isotropic=isotropic)\n",
    "    X = sfm.design_matrix\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.data import get_fnames\n",
    "from dipy.core.gradients import gradient_table\n",
    "\n",
    "fdata, fbvals, fbvecs = get_fnames(\"sherbrooke_3shell\")\n",
    "gtab = gradient_table(fbvals, fbvecs, b0_threshold=0)\n",
    "img = nib.load(fdata)\n",
    "data = img.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We fix b0 to be one volume, registered to one of the\n",
    "# # b0 volumes (first, per default):\n",
    "# if np.sum(gtab.b0s_mask) > 1:\n",
    "#     b0_img = nib.Nifti1Image(data[..., gtab.b0s_mask], affine)\n",
    "#     trans_b0, b0_affines = dpa.register_series(b0_img, ref=b0_ref)\n",
    "#     ref_data = np.mean(trans_b0, -1)[..., np.newaxis]\n",
    "# else:\n",
    "#     # There's only one b0 and we register everything to it\n",
    "#     trans_b0 = ref_data = data[..., gtab.b0s_mask]\n",
    "\n",
    "# moving_data = data[..., ~gtab.b0s_mask]\n",
    "# moving_bvals = gtab.bvals[~gtab.b0s_mask]\n",
    "# moving_bvecs = gtab.bvecs[~gtab.b0s_mask]\n",
    "# mask = np.ones(ref_data.shape[:3])\n",
    "# mask[np.where(ref_data[..., 0] == 0)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loo = 0 \n",
    "# loo_idxer = np.ones(moving_data.shape[-1]).astype(bool)\n",
    "# loo_idxer[loo] = False\n",
    "\n",
    "# in_data = np.concatenate([ref_data, moving_data[..., loo_idxer]], -1)\n",
    "# in_gtab = dpg.gradient_table(\n",
    "#     np.concatenate([np.array([0]), moving_bvals[loo_idxer]]),\n",
    "#     np.concatenate([np.array([[0, 0, 0]]), moving_bvecs[loo_idxer]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfm = SFM4HMC(\n",
    "#     in_gtab,\n",
    "#     isotropic=ExponentialIsotropicModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sff = sfm.fit(in_data, mask=mask, frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = sff.predict(in_gtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(in_data[64, 64, 30])\n",
    "# plt.plot(pred[64, 64, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_data = moving_data[..., ~loo_idxer]\n",
    "# out_gtab = dpg.gradient_table(moving_bvals[~loo_idxer],\n",
    "#                                 moving_bvecs[~loo_idxer])\n",
    "\n",
    "# out_pred = sff.predict(out_gtab, S0=ref_data[..., 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_data.shape, out_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo = np.sqrt((out_data[:, :, 30, 0] - out_pred[:, :, 30])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(out_data[:, :, 30])\n",
    "# plt.matshow(out_pred[:, :, 30], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(out_data), np.max(out_pred), np.min(out_data), np.min(out_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmc(data, gtab, mask=None, b0_ref=0, affine=None):\n",
    "    data, affine = read_img_arr_or_path(data, affine=affine)\n",
    "    if isinstance(gtab, collections.Sequence):\n",
    "        gtab = dpg.gradient_table(*gtab)\n",
    "\n",
    "    # We fix b0 to be one volume, registered to one of the\n",
    "    # b0 volumes (first, per default):\n",
    "    if np.sum(gtab.b0s_mask) > 1:\n",
    "        b0_img = nib.Nifti1Image(data[..., gtab.b0s_mask], affine)\n",
    "        trans_b0, b0_affines = dpa.register_series(b0_img, ref=b0_ref)\n",
    "        ref_data = np.mean(trans_b0, -1)[..., np.newaxis]\n",
    "    else:\n",
    "        # There's only one b0 and we register everything to it\n",
    "        trans_b0 = ref_data = data[..., gtab.b0s_mask]\n",
    "\n",
    "    moving_data = data[..., ~gtab.b0s_mask]\n",
    "    moving_bvals = gtab.bvals[~gtab.b0s_mask]\n",
    "    moving_bvecs = gtab.bvecs[~gtab.b0s_mask]\n",
    "    mask = np.ones(ref_data.shape[:3])\n",
    "    mask[np.where(ref_data[..., 0] == 0)] = 0\n",
    "    moved = []\n",
    "    affines = []\n",
    "    print(moving_data.shape[-1])\n",
    "    for loo in range(2): #range(moving_data.shape[-1]):\n",
    "        print(loo)\n",
    "        loo_idxer = np.ones(moving_data.shape[-1]).astype(bool)\n",
    "        loo_idxer[loo] = False\n",
    "\n",
    "        in_data = np.concatenate([ref_data, moving_data[..., loo_idxer]], -1)\n",
    "        in_gtab = dpg.gradient_table(\n",
    "            np.concatenate([np.array([0]), moving_bvals[loo_idxer]]),\n",
    "            np.concatenate([np.array([[0, 0, 0]]), moving_bvecs[loo_idxer]]))\n",
    "\n",
    "        sfm = SFM4HMC(\n",
    "            in_gtab,\n",
    "            isotropic=ExponentialIsotropicModel)\n",
    "\n",
    "        t1 = time.time()\n",
    "        sff = sfm.fit(in_data, mask=mask, frac=10e-10)\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        out_data = moving_data[..., ~loo_idxer]\n",
    "        out_gtab = dpg.gradient_table(moving_bvals[~loo_idxer],\n",
    "                                      moving_bvecs[~loo_idxer])\n",
    "\n",
    "        out_pred = sff.predict(out_gtab, S0=ref_data[..., 0])\n",
    "        t1 = time.time()\n",
    "        resampled, starting_affine = dpa.affine_registration(\n",
    "            out_data[..., 0],\n",
    "            out_pred,\n",
    "            moving_affine=affine,\n",
    "            static_affine=affine,\n",
    "            pipeline=[dpa.affine],\n",
    "            level_iters=[10])\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        moved.append(resampled)\n",
    "        affines.append(starting_affine)\n",
    "        in_data[..., loo] = resampled\n",
    "        # XXX Also rotate the b-vector here\n",
    "\n",
    "# Reuse USV from a single SVD decomposition of X at the beginning of each\n",
    "# loop through all of the volumes. Should speed up the RR fit in every volume.\n",
    "\n",
    "# Use a sliding window to fit only to n nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%lprun` not found.\n"
     ]
    }
   ],
   "source": [
    "%lprun -f SFM4HMC.fit hmc(data, gtab, mask=None, b0_ref=0, affine=img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 60, 193)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
